<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab 12: Path Planning and Execution</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            padding: 20px;
            background-color: #f4f4f4;
        }
        h1, h2, h3, h4 {
            color: #333;
        }
        .container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.1);
        }
        p {
            line-height: 1.6;
        }
        img, iframe {
            width: 500px;
            height: auto;
            display: block;
            margin: 10px auto;
        }
        pre {
            background: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <div class="container">

<h1>Lab 12: Path Planning and Execution</h1>

<h3>Objective</h3>
<p>
    The goal of this lab was to demonstrate autonomous path execution by integrating robot motion control with pre-defined waypoint navigation. 
    Building upon the functionality developed in previous labs, this final exercise aimed to create a complete system capable of reliably following 
    a multi-point path across a mapped environment.
</p>

<h3>Strategy</h3>
<p>
    My approach centered around writing BLE command functions in Python that could be easily edited, tuned, and executed without 
    needing to re-upload code to the Artemis board. The strategy was intentionally simple: rely on <strong>open-loop timed control</strong> to move the
    robot forward or execute turns. 
</p>
<p>
    Two basic commands were used:
</p>
<ul>
    <li><code>FORWARD_TIME_PWM</code>: Drive forward for a set time and PWM</li>
    <li><code>TURN_DIR_TIME</code>: Turn left (2) or right (1) for a set time and PWM</li>
</ul>

        <img src="fwd.png" alt=". ">
        <img src="trn.png" alt=".">
        

<h3>Execution Path</h3>
<p>The robot followed these waypoints:</p>
<pre>
(-4, -3) → (-2, -1) → (1, -1) → (2, -3) → (5, -3) 
       → (5, -2) → (5, 3) → (0, 3) → (0, 0)
</pre>

<h3>Implementation</h3>
<p>
    I manually calibrated each segment by iterating trial runs, adjusting time durations in seconds through using the python commands.  
    I found that even the same command could behave differently across trials due to minor inconsistencies in the battery level, so frequent re-tuning was necessary.
</p>

<h4>My Control Script:</h4>
        <img src="cal.png" alt=". ">

<h4>My Control Script Used to Test & Iterate:</h4>
        <img src="calib.png" alt=". ">
        

<p>
    This control logic proved effective for quickly testing variations in path timing. All planning and command sequencing happened offboard on the host computer.
</p>

<h3>Performance and Observations</h3>
<p>
    The robot completed the full waypoint path reliably in multiple trials. While open-loop control lacks the precision of feedback-based methods, 
    the combination of BLE commands and time-based execution was sufficient to complete the task.
</p>
<p>
    The largest sources of error were due to:
</p>
<ul>
    <li>Battery degradation affecting PWM consistency</li>
    <li>Wheel slip causing slight drift over turns and occasional overshoot</li>
</ul>

<h3>Conclusion</h3>
<p>
    This lab showcased a functional end-to-end navigation pipeline built from modular BLE commands. 
    While feedback control could offer improved precision, my open-loop method was a fast, testable, and robust solution for 
    waypoint navigation using calibrated motion segments.
</p>
        <h4>Video of Robot Executing the Route:</h4>
<iframe width="500" height="300" src="https://www.youtube.com/embed/7x0yh9zGuh8" frameborder="0" allowfullscreen></iframe>


<a href="../index.html">Back to Main Page</a>

</div>
</body>
</html>

